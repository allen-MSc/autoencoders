{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RVnRHiD_3IFS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBFydOMH3asU",
        "outputId": "ce1d84b9-5b2b-4e73-cab0-aa3faf953c24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_high_low_loaders(data_set):\n",
        "  train_idx_h = [h for h in range(len(data_set.targets)) if data_set.targets[h] == 0]\n",
        "  train_idx_l = [l for l in range(len(data_set.targets)) if data_set.targets[l] == 1]\n",
        "\n",
        "  # high resolution\n",
        "  train_set_h = torch.utils.data.Subset(data_set, train_idx_h)\n",
        "  train_loader_h = torch.utils.data.DataLoader(dataset=train_set_h, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  # low resolution\n",
        "  train_set_l = torch.utils.data.Subset(data_set, train_idx_l)\n",
        "  train_loader_l = torch.utils.data.DataLoader(dataset=train_set_l, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader_h, train_loader_l\n"
      ],
      "metadata": {
        "id": "ruv-efqzhYTk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbl5_2KaE-vN",
        "outputId": "87a4f2d7-71ce-46ef-9887-9e65a763a550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 1370\n",
            "    Root location: /content/drive/MyDrive/UTEC/ciclo2/Aprendizaje Automático/Semana13_PROY4_Autoencoders/dataset/train/\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 340\n",
            "    Root location: /content/drive/MyDrive/UTEC/ciclo2/Aprendizaje Automático/Semana13_PROY4_Autoencoders/dataset/val/\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "img_transform = transform.Compose([transform.ToTensor()]) \n",
        "\n",
        "# Training Set\n",
        "train_set =  torchvision.datasets.ImageFolder('/content/drive/MyDrive/UTEC/ciclo2/Aprendizaje Automático/Semana13_PROY4_Autoencoders/dataset/train/', img_transform)\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(train_set)\n",
        "\n",
        "# Testing Set\n",
        "test_set =  torchvision.datasets.ImageFolder('/content/drive/MyDrive/UTEC/ciclo2/Aprendizaje Automático/Semana13_PROY4_Autoencoders/dataset/val/', img_transform)\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_features = 40"
      ],
      "metadata": {
        "id": "vj0Gv-OHDqUC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.size_output_layer(256,3,2,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTrsD0FRHNDJ",
        "outputId": "503f7f63-b4ef-4990-f0ab-d71fcbd2cae1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "utils.size_output_layer(128,3,2,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIg3yYPmHpTA",
        "outputId": "165c53d8-8fb8-42e6-96c1-2d49968423a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qAfqrQ5vHxYh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xx616fTKFK_n"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1), #salida \n",
        "      #nn.BatchNorm2d(64),#out_channels\n",
        "      nn.ReLU()\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64, out_channels=64*2, kernel_size=4, stride=2, padding=1), #salida 128\n",
        "      #nn.BatchNorm2d(64*2),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.conv3 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64*2, out_channels=64*2*2, kernel_size=4, stride=2, padding=1), # salida 32\n",
        "      #nn.BatchNorm2d(64*2*2),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Linear(in_features=64*2*2*64*64, out_features=_features)\n",
        "\n",
        "  def forward(self, image):\n",
        "    self.out1 = F.relu(self.conv1(image))\n",
        "    self.out2 = F.relu(self.conv2(self.out1))\n",
        "    self.out3 = F.relu(self.conv3(self.out2))\n",
        "    self.out4 = self.out3.view(self.out3.size(0), -1)\n",
        "    z = self.fc(self.out4)\n",
        "    return z\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.fc    = nn.Linear(in_features=_features,out_features=64*2*2*64*64)\n",
        "    self.convTran1 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=2*2*2*64,out_channels=64*2, kernel_size=4, stride=2, padding=1),\n",
        "        #nn.BatchNorm2d(64*2),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.convTran2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=2*64*2,out_channels=64, kernel_size=4, stride=2, padding=1),\n",
        "        #nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.convTran3 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=3, stride=1, padding=1),\n",
        "        #nn.BatchNorm2d(3),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "   \n",
        "  def forward(self, latent, encoder):\n",
        "    out = self.fc(latent)\n",
        "    out = out.view(out.size(0), 64*2*2, 64, 64)\n",
        "    # out = F.relu(self.convTran1(out))\n",
        "    out = F.relu(self.convTran1(torch.cat([out, encoder.out3], dim=1)))\n",
        "\n",
        "    out = F.relu(self.convTran2(torch.cat([out, encoder.out2], dim=1)))\n",
        "\n",
        "    # out = torch.tanh(self.convTran2(out))\n",
        "    out = torch.tanh(self.convTran3(torch.cat([out, encoder.out1], dim=1)))\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kRFF_5QaHA8I"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "   def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "   def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        x_recon = self.decoder(latent, self.encoder)\n",
        "        return  x_recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3gfxVuePHEW2"
      },
      "outputs": [],
      "source": [
        "def train(model, images_set, Epochs, loss_fn):\n",
        "\n",
        "    images_high_loader, images_low_loader = get_high_low_loaders(images_set)\n",
        "\n",
        "    train_loss_avg = []\n",
        "    for epoch in range(Epochs):\n",
        "      train_loss_avg.append(0)\n",
        "      num_batches = 0\n",
        "\n",
        "      images_high_it = iter(images_high_loader)\n",
        "    \n",
        "      for image_batch, _ in tqdm(images_low_loader):\n",
        "          image_batch = image_batch.to(device)\n",
        "          \n",
        "          image_batch_recon = model(image_batch)\n",
        "\n",
        "          image_batch_high, _ = next(images_high_it)\n",
        "          image_batch_high = image_batch_high.to(device)\n",
        "          \n",
        "          loss = loss_fn(image_batch_recon, image_batch_high)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          train_loss_avg[-1] += loss.item()\n",
        "          num_batches += 1\n",
        "          \n",
        "      train_loss_avg[-1] /= num_batches\n",
        "      print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, Epochs, train_loss_avg[-1]))\n",
        "    return train_loss_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TViDJlP-HJR1",
        "outputId": "700f521a-20c3-4566-9b62-c6a43867516a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:52<00:00,  2.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 10] average reconstruction error: 0.125514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:50<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2 / 10] average reconstruction error: 0.094213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:50<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3 / 10] average reconstruction error: 0.092756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:50<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4 / 10] average reconstruction error: 0.092412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:50<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5 / 10] average reconstruction error: 0.091946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:50<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6 / 10] average reconstruction error: 0.091483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:50<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7 / 10] average reconstruction error: 0.091286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:50<00:00,  2.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8 / 10] average reconstruction error: 0.091166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 5/22 [00:11<00:39,  2.32s/it]"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "autoencoder = Autoencoder()\n",
        "autoencoder.to(device)\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(params=autoencoder.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "autoencoder.train()\n",
        "\n",
        "loss_result = train(autoencoder, train_set, 10, loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4do5lwRMRVz"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(loss_result)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Reconstruction error')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KiiSvzuLHfk"
      },
      "outputs": [],
      "source": [
        "test_high_loader, test_low_loader = get_high_low_loaders(test_set)\n",
        "\n",
        "autoencoder.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  image, label = iter(test_low_loader).next()\n",
        "\n",
        "  image = image.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  z = autoencoder.encoder(image)\n",
        "  z = z.to(device)\n",
        "\n",
        "  decodificado = autoencoder.decoder(z, autoencoder.encoder)\n",
        "  decodificado = decodificado.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_img = 1;\n",
        "images_l, _ = iter(test_low_loader).next()\n",
        "images_h, _ = iter(test_high_loader).next()\n",
        "\n",
        "fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, sharex=True, figsize=(20, 20))\n",
        "ax0.set_title('Test Image (low resolution)')\n",
        "ax0.imshow(transform.ToPILImage()(images_l[idx_img]))\n",
        "\n",
        "ax1.set_title('Predicted Image')\n",
        "ax1.imshow(transform.ToPILImage()(decodificado[idx_img]))\n",
        "\n",
        "ax2.set_title('Original Image (high resolution)')\n",
        "ax2.imshow(transform.ToPILImage()(images_h[idx_img]))"
      ],
      "metadata": {
        "id": "ul9bVm_jj5jL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "proyecto4_avance2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}